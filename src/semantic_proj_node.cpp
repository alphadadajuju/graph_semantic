// ROS
#include <ros/ros.h>
#include <tf/transform_broadcaster.h>

// ROS messags
#include "visualization_msgs/Marker.h"
#include "std_msgs/String.h"
#include <std_msgs/Int16.h>
#include "graph_semantic/FusedPointcloud.h"
#include "graph_semantic/RGB2LabelProb.h"

#include "std_msgs/MultiArrayDimension.h"
#include "std_msgs/Float32MultiArray.h"


// C++
#include "boost/filesystem.hpp"
#include <iostream>
#include <fstream>
#include <string>
#include <sstream>
#include <float.h>
#include <cmath>

// OpenCV
#include <cv_bridge/cv_bridge.h>
#include <opencv2/highgui/highgui.hpp>  
#include <image_geometry/pinhole_camera_model.h>

// Eigen
#include <Eigen/Geometry>

// PCL
#include <pcl/point_types.h>
#include <pcl/point_cloud.h>
#include <pcl/io/ply_io.h>
#include <pcl_conversions/pcl_conversions.h>
#include <pcl/PCLPointCloud2.h>
#include <pcl/conversions.h>
#include <pcl_ros/transforms.h>
#include <pcl/filters/frustum_culling.h>
#include <pcl/visualization/common/common.h>
#include <pcl/filters/passthrough.h>
#include <pcl_ros/transforms.h>
#include <pcl/filters/extract_indices.h>

#include <pcl/features/normal_3d.h>
#include <pcl/kdtree/kdtree.h>

// CRF
#include "CRF/densecrf.h"


using namespace std;

// read camera poses (in map's frame) from pose.txt (generated by RTabMap)
void read_poses(const std::string &name, vector<Eigen::Matrix4f> &v){
    ifstream inFile;
    inFile.open(name);

    if (!inFile)
        ROS_ERROR_STREAM("Unable to open file pose.txt");

    float val;
    while (inFile >> val){
        Eigen::Matrix4f pose;
        pose(0,0) = val;

        // construct 3x4 camera pose matrix
        for (int i = 0; i < 3; i++){
            for(int j = 0; j < 4; j++){
                if (i == 0 && j == 0) continue;
                inFile >> val;
                pose(i,j) = val;

            }
        }
        
        // Fill in last row
        pose(3,0) = 0; pose(3,1) = 0; pose(3,2) = 0; pose(3,3) = 1;
        v.push_back(pose);
    }
}

// read RGB images (generated by RTabMap); each image corresponds to a camera pose
void read_directory(const string& name, vector<string> &v){
    try{
        boost::filesystem::path p(name);
        boost::filesystem::directory_iterator start(p);
        boost::filesystem::directory_iterator end;

        // get files in the directory
        vector<boost::filesystem::path> paths;
        std::copy(start, end, back_inserter(paths));


        // sort RGB images in sequence based on filename (1->2->3...)
        struct custom_sort_func{
            // Return true if b bigger than a, false if equal or smaller
            bool operator()(const boost::filesystem::path &a, const boost::filesystem::path &b){
                if (a.string().size() == b.string().size())
                    return a.compare(b) < 0;
                else
                    return a.string().size() < b.string().size();
            }
        } custom_sort;
        
        std::sort(paths.begin(), paths.end(), custom_sort);

        for (vector<boost::filesystem::path>::const_iterator it(paths.begin()); it != paths.end(); it++){
            v.push_back(it->string());
        }


    }catch(const boost::filesystem::filesystem_error &ec){
        cout << ec.what() << '\n';
    }
}

class SemanticFusion{
private:
    int num_labels;                 // number of classes
    cv::Mat label2bgr;              // label-to-color mapping reference

    ros::NodeHandle nh;             // node handler
    ros::Publisher marker_pub;      // camera pose in map frame
    ros::Publisher pc_display_pub;  // rgb (turned gray) pc before label backprojection
    ros::Publisher fused_pc_pub;    // labeled pc
    ros::ServiceClient segnet_client; // calls SegNet to perform 2-D semantic segmentation

    // wraps a matrix into a multiarray for data transport
    void matrix2multiarray(const vector<vector<float>> &label_prob, std_msgs::Float32MultiArray &msg_out);
    
    // display camera pose in map frame
    void displayCameraMarker(Eigen::Matrix4f cam_pose);
    
    // display labeled pointcloud (label mapped to perceivable RGB colors)
    void displayPointcloud(const pcl::PointCloud<pcl::PointXYZRGB> &pc);
    
    // per pointcloud's point, map each label to a RGB color
    void createLabelsInRGBPointcloud(const pcl::PointCloud<pcl::PointXYZRGB> &pc, 
                                     const vector<vector<float>> &label_prob,
                                     pcl::PointCloud<pcl::PointXYZL> &labeled_pc,
                                     pcl::PointCloud<pcl::PointXYZRGB> &rgb_labeled_pc);

    void regularizePointcloud(const pcl::PointCloud<pcl::PointXYZRGB> &cloud_in, 
                              const vector<vector<float>> &label_prob_in, 
                              vector<vector<float>> &label_prob_reg);

    void regularizePointcloudFrame(const pcl::PointCloud<pcl::PointXYZRGB> &cloud_in,
                                          vector<int> &inside_indices,
                                          const vector<vector<float>> &label_prob_in, 
                                          vector<vector<float>> &label_prob_out);


public:
    SemanticFusion();
    bool debug_mode;      // if debug_mode, display results INCREMENTALLY (by frame)
    bool regularize_frame;

    // load camera's pose.txt and RGB images scanned at a place
    bool loadPlaceData(const string &base_path, pcl::PointCloud<pcl::PointXYZRGB> &pc, vector<Eigen::Matrix4f> &poses, vector<string> &images);
    
    // CORE: Bayesian backprojecting 2-D semantic label to the corresponding point in 3-D space
    // Use frustumculling to find the 3-D points corresponding to 2-D pixels
    void createFusedSemanticMap(const string &base_path, const pcl::PointCloud<pcl::PointXYZRGB> &pc, const vector<Eigen::Matrix4f> &poses, const vector<string> &images);
    
    // save each point's class probability (for CRF point-wise regularization)
    void storePointsProbDist(const string &base_path, const vector<vector<float> > &label_prob);

    void loadAndPublishLabeledPointcloud(string path);

    void loadPointsProbDist(const string &label_probs_path, vector<vector<float>> &label_prob);
};

SemanticFusion::SemanticFusion(){
    debug_mode = true;

    num_labels = -1; // if ros::param is not set, prohibits further processing
    ros::param::get("graph_semantic/num_labels", num_labels);
    
    // read label-to-color mapping image
    string caffe_model_path;
    ros::param::get("graph_semantic/caffe_model_path", caffe_model_path);
    string label2bgr_filepath = caffe_model_path + "/sun_redux.png";

    label2bgr = cv::imread(label2bgr_filepath, CV_LOAD_IMAGE_COLOR); 

    // subscriber, publisher and service
    pc_display_pub = nh.advertise<sensor_msgs::PointCloud2>("graph_semantic/fusion_pointcloud", 10);
    marker_pub = nh.advertise<visualization_msgs::Marker>("graph_semantic/camera_pose", 10); 
    fused_pc_pub = nh.advertise<graph_semantic::FusedPointcloud>("graph_semantic/semantic_fused_pc", 10); 
    
    ros::service::waitForService("rgb_to_label_prob", 12);
    segnet_client = nh.serviceClient<graph_semantic::RGB2LabelProb>("rgb_to_label_prob");
    ros::Duration(1).sleep();

}


// load camera's pose.txt and RGB images scanned at a place
bool
SemanticFusion::loadPlaceData(const string &base_path, pcl::PointCloud<pcl::PointXYZRGB> &pc, vector<Eigen::Matrix4f> &poses, vector<string> &images){

    ROS_INFO_STREAM("semantic_proj_node: " << " processing directory " << base_path);  
    
    boost::filesystem::path p(base_path);
    if (!boost::filesystem::exists(base_path))
        ROS_ERROR_STREAM("semantic_proj_node: Invalid base-path for loading place data");

    // load globally registered pointcloud
    string pc_path = base_path + "cloud.ply";
    pcl::io::loadPLYFile(pc_path, pc);

    // load camera poses
    string poses_path = base_path + "poses.txt";
    read_poses(poses_path, poses);

    // load RGB images
    string rgb_path = base_path + "rgb";
    read_directory(rgb_path, images);

    ROS_INFO_STREAM("proj_node: " << " loaded cloud with " << pc.points.size() << " points.");
    ROS_INFO_STREAM("proj_node: " << " loaded " << poses.size() << " poses.");
    ROS_INFO_STREAM("proj_node: " << " loaded " << images.size() << " image's path.");

    return true;
}

// CORE: Bayesian backprojecting 2-D semantic label to the corresponding point in 3-D space
// Use frustumculling to find the 3-D points corresponding to 2-D pixels
void SemanticFusion::createFusedSemanticMap(const string &base_path, const pcl::PointCloud<pcl::PointXYZRGB> &pc,
                                            const vector<Eigen::Matrix4f> &poses, const vector<string> &images) {

    ROS_INFO_STREAM("Inside createFusedSemanticMap!");

    // Initialize label probability structure
    vector<float> label_prob_init(num_labels, 1.0f / (1.0f * num_labels));
    vector<vector<float> > label_prob(pc.points.size(), label_prob_init);  

    // Initialize frustum instance
    pcl::FrustumCulling<pcl::PointXYZRGB> fc;
    fc.setInputCloud ( pc.makeShared() );
    fc.setVerticalFOV (45);
    fc.setHorizontalFOV (58);
    fc.setNearPlaneDistance (0.5);
    fc.setFarPlaneDistance (6);

    // P: intrinsic matrix from CameraInfo
    Eigen::Matrix4f P;
    //P << 525.0, 0.0, 319.5, 0.0, 0.0, 525.0, 239.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0;  // for Kinect V1
    P << 570.34222412109375, 0., 319.5, 0., 0.0, 570.34222412109375, 239.5, 0., 0., 0.0, 1., 0.0, 0.0, 0.0, 0.0, 1.0; // for Asus Xtion


    // for each camera pose, project segmented 2-D labels into corresponding 3-D points 
    for (int i = 0; i < poses.size(); i++){
        ROS_INFO_STREAM_THROTTLE(5, "Processing node " << i << "/" << poses.size());
        if(!ros::ok()) return;

        // Frustrumcilling from poses -> indices of visible points
        // Hard-coded cam orientation between world and map
        Eigen::Matrix3f rot_camera;
        rot_camera = Eigen::AngleAxisf( -0.5f*M_PI, Eigen::Vector3f::UnitZ())
            * Eigen::AngleAxisf( 0.0f*M_PI, Eigen::Vector3f::UnitY())
            * Eigen::AngleAxisf( -0.5f*M_PI, Eigen::Vector3f::UnitX());

        Eigen::Matrix4f rot4 = Eigen::Matrix4f::Identity(4,4);
        rot4.topLeftCorner(3,3) = rot_camera; // tf world -> map

        // cam pose in world == pose in map * inverse (tf(world->map))
        Eigen::Matrix4f cam_pose_world =  poses[i] * rot4.inverse();


        fc.setCameraPose(cam_pose_world);
        std::vector<int> inside_indices; // Indices of points in pc_gray inside camera frustrum at pose[i]
        fc.filter(inside_indices);

        ROS_INFO_STREAM("In frame " << i <<"," << inside_indices.size() << " points!");

        
        // SRV: request image labeling through SegNet
        cv::Mat cv_img = cv::imread(images[i], CV_LOAD_IMAGE_COLOR);
        sensor_msgs::ImagePtr image_msg = cv_bridge::CvImage(std_msgs::Header(), "bgr8", cv_img).toImageMsg();
        graph_semantic::RGB2LabelProb srv_msg;
        srv_msg.request.rgb_image = *image_msg.get(); // boost share pointer
        segnet_client.call(srv_msg);
        
        // Display RGB image in Rviz to match server's time of publication
        sensor_msgs::ImagePtr rgb_img_msg = cv_bridge::CvImage(std_msgs::Header(), "bgr8", cv_img).toImageMsg();

        // wrap class probability distribution of all pixels into multiarray
        std_msgs::Float32MultiArray frame_label_probs(srv_msg.response.image_class_probability);
        int dim_stride_1 = frame_label_probs.layout.dim[1].stride;
        int dim_stride_2 = frame_label_probs.layout.dim[2].stride;

        
        // transform from Rviz depth camera frame to CV rgb camera frame
        Eigen::Matrix4f rviz2cv = Eigen::Matrix4f::Identity(4,4);
        Eigen::Matrix3f r;
        r = Eigen::AngleAxisf(0.0f*M_PI, Eigen::Vector3f::UnitZ())
            * Eigen::AngleAxisf( -0.5f*M_PI, Eigen::Vector3f::UnitY())
            * Eigen::AngleAxisf( 0.5f*M_PI, Eigen::Vector3f::UnitX());
        rviz2cv.topLeftCorner(3,3) = r;

        Eigen::Matrix4f depth2optical = Eigen::Matrix4f::Identity(4,4);
        depth2optical(0,3) = -0.045f; //-0.025

        
        Eigen::Matrix4f pose_inv = cam_pose_world.inverse();

        
        // final transformation: 3-D point -> 2-D pixel
        Eigen::Matrix4f world2pix = P * depth2optical * rviz2cv * pose_inv;

        //Create "Z buffer" emulator to store the distance of each 3-D point to the camera position
        int pixel_point_proj[480][640];
        float pixel_point_dist[480][640];
        fill_n(&pixel_point_proj[0][0], sizeof(pixel_point_proj) / sizeof(**pixel_point_proj), -1);
        fill_n(&pixel_point_dist[0][0], sizeof(pixel_point_dist) / sizeof(**pixel_point_dist), FLT_MAX);


        for(std::vector<int>::iterator it = inside_indices.begin(); it != inside_indices.end(); it++){
    
            // Backproject points using camera matrix (discard out of range)
            Eigen::Vector4f point_w(pc.points[*it].x, pc.points[*it].y, pc.points[*it].z, 1.0);
            Eigen::Vector4f point_px = world2pix * point_w;


            if(point_px(2) == 0){ point_px(2) +=1; } // Adapt homogenous for 4x4 efficient multiplication

            int pix_x = (int) std::round(point_px(0)/point_px(2));
            int pix_y = (int) std::round(point_px(1)/point_px(2));

            if(pix_x < 0 || pix_x >= 640 || pix_y < 0 || pix_y >= 480)
                continue;

            //Compute distance from camera position to point position
            Eigen::Vector3f cam_point_vec(cam_pose_world(0,3)-pc.points[*it].x,
                                          cam_pose_world(1,3)-pc.points[*it].y,
                                          cam_pose_world(2,3)-pc.points[*it].z);
            float cam_point_dist = cam_point_vec.norm();

            //Check against tables and ONLY keep closest point's index
            if(cam_point_dist < pixel_point_dist[pix_y][pix_x]){
                
                pixel_point_proj[pix_y][pix_x] = *it;
                pixel_point_dist[pix_y][pix_x] = cam_point_dist;
            }

        }


        // get associated prob distributions; multiply distributions together and renormalize (Bayesian)
        for (int y = 0; y < 480; ++y) {
            for (int x = 0; x < 640; ++x) {
                if(pixel_point_proj[y][x] == -1){ // no valid backprojection
                    continue;
                }
                //Get idx of nearest projected point from pointcloud (will ONLY project 2-D label to the nearest 3-D point)
                int pc_idx = pixel_point_proj[y][x];

                // Multiply each element of the distribution and Get the sum of the final distribution
                float prob_dist_sum = 0.0;
                for (int cl = 0; cl < num_labels; cl++) {
                    label_prob[pc_idx][cl] *= frame_label_probs.data[dim_stride_1*y + dim_stride_2*x + cl];
                    prob_dist_sum += label_prob[pc_idx][cl];
                }

                // Divide each element by the sum so that they add up to 1
                for (int cl = 0; cl < num_labels; cl++) {
                    label_prob[pc_idx][cl] /= prob_dist_sum;
                }


            }
        }

        ros::param::get("regularize_frame", regularize_frame);
        // incrementally displays fused pointcloud in Rviz for every camera pose
        if(debug_mode){
            pcl::PointCloud<pcl::PointXYZL> labeled_pc;
            pcl::PointCloud<pcl::PointXYZRGB> label_rgb_pc;

            // initialize pointcloud and label_prob of only the current frame
            

            
            if(regularize_frame){
                vector<vector<float>> label_prob_reg;
                //regularizePointcloud(pc, label_prob, label_prob_reg);
                regularizePointcloudFrame(pc, inside_indices, label_prob, label_prob_reg);
                //copy(label_prob_reg.begin(), label_prob_reg.end(), label_prob);
                label_prob = label_prob_reg;
            }
            

            createLabelsInRGBPointcloud(pc, label_prob, labeled_pc, label_rgb_pc);
            displayCameraMarker(cam_pose_world);
            displayPointcloud(label_rgb_pc);
        }
    }

    pcl::PointCloud<pcl::PointXYZL> labeled_pc;
    pcl::PointCloud<pcl::PointXYZRGB> label_rgb_pc;


    vector<vector<float>> label_prob_reg;
    regularizePointcloud(pc, label_prob, label_prob_reg);
    label_prob = label_prob_reg;
    
    createLabelsInRGBPointcloud(pc, label_prob, labeled_pc, label_rgb_pc);
    displayPointcloud(label_rgb_pc);
    
    // store pointcloud
    string labeled_cloud_path = base_path + "labeled_cloud.ply";
    string labeled_cloud_rgb_path = base_path + "labeled_cloud_rgb.ply";
    string label_probs_path = base_path + "label_probabilities.txt";

    pcl::io::savePLYFile(labeled_cloud_path, labeled_pc, true);
    pcl::io::savePLYFile(labeled_cloud_rgb_path, label_rgb_pc, true);
    storePointsProbDist(label_probs_path, label_prob);

    // create pointcloud message
    sensor_msgs::PointCloud2 labeled_pc_msg;
    pcl::toROSMsg(labeled_pc, labeled_pc_msg);
    labeled_pc_msg.header.frame_id = "map";

    // create probabilities message
    std_msgs::Float32MultiArray label_prob_msg;
    matrix2multiarray(label_prob, label_prob_msg);


    // Publish both
    graph_semantic::FusedPointcloud fused_pc_msg;
    fused_pc_msg.labelled_pc = labeled_pc_msg;
    fused_pc_msg.label_probs = label_prob_msg;
    fused_pc_pub.publish(fused_pc_msg);

    ROS_INFO_STREAM("Fused pointcloud complete and published!");
  
}

void SemanticFusion::regularizePointcloudFrame(const pcl::PointCloud<pcl::PointXYZRGB> &cloud_in,
                                          vector<int> &inside_indices,
                                          const vector<vector<float>> &label_prob_in, 
                                          vector<vector<float>> &label_prob_out){
    
    ROS_INFO_STREAM("Regularizing frame:");

    // copy points inside frustum
    pcl::PointCloud<pcl::PointXYZRGB> cloud_frame;
    pcl::copyPointCloud(cloud_in, inside_indices, cloud_frame);

    // initialize prob out
    copy(label_prob_in.begin(), label_prob_in.end(), back_inserter(label_prob_out));


    // copy associated prob distributions
    vector<float> label_prob_init(num_labels, 1.0f / (1.0f * num_labels));
    vector<vector<float> > label_prob_frame(cloud_frame.points.size(), label_prob_init);  
    int it_reg = 0;
    for(vector<int>::iterator it = inside_indices.begin(); it != inside_indices.end(); it++){
        for (int cl = 0; cl < num_labels; cl++) {
            label_prob_frame[it_reg][cl] = label_prob_in[*it][cl];
        }
        it_reg++;
    }   

    // initialize container for temp storage of label prob frame after regularization
    vector<vector<float>>label_prob_frame_out = label_prob_frame;

    // create the normal estimation instance
    pcl::NormalEstimation<pcl::PointXYZRGB, pcl::Normal> ne;
    pcl::search::KdTree<pcl::PointXYZRGB>::Ptr tree (new pcl::search::KdTree<pcl::PointXYZRGB> ());
    ne.setSearchMethod (tree);
    ne.setRadiusSearch (0.03);

    ne.setInputCloud (cloud_frame.makeShared());
    pcl::PointCloud<pcl::Normal>::Ptr cloud_normals (new pcl::PointCloud<pcl::Normal>);
    ne.compute (*cloud_normals);

    // emulate data structure for each cloud's point 
    int surfel_size = 7; 
    float * my_surfels = new float[label_prob_frame.size() * surfel_size];

    // fill in surfel data for each point
    for(int i = 0; i < label_prob_frame.size(); i++){

        // add x,y,z position as floats on positions 0, 1, 2
        my_surfels[i*surfel_size + 0] = cloud_frame.points[i].x;
        my_surfels[i*surfel_size + 1] = cloud_frame.points[i].y;
        my_surfels[i*surfel_size + 2] = cloud_frame.points[i].z;

        // add 32bit encoded rgb color on position 4
        int colour = cloud_frame.points[i].r;
        colour = (colour << 8) + cloud_frame.points[i].g;
        colour = (colour << 8) + cloud_frame.points[i].b;
        my_surfels[i*surfel_size + 3] = colour;

        // Add x,y,z components of normal vector on positions 8, 9, 10
        my_surfels[i*surfel_size + 4] = cloud_normals->points[i].normal_x;
        my_surfels[i*surfel_size + 5] = cloud_normals->points[i].normal_y;
        my_surfels[i*surfel_size + 6] = cloud_normals->points[i].normal_z;

    }

    vector<int> valid_ids;
    for (int i = 0; i < label_prob_frame.size(); i++) {
        valid_ids.push_back(i);
    }


    // generate unary energies
    vector<float> unary_potentials(label_prob_frame.size() * num_labels);
    for (int i = 0; i < label_prob_frame.size(); i++) {
        for (int j = 0; j < label_prob_frame[0].size();j++) {
            unary_potentials[i * num_labels + j] = -log10(label_prob_frame[i][j] + 1.0e-6f);
        }
    }

    ROS_INFO_STREAM("CRF begin!");
    // CRF
    DenseCRF3D crf((int) cloud_frame.points.size(), num_labels, 0.05, 20, 0.1);

    // Add unary energies
    crf.setUnaryEnergy(unary_potentials.data());

    // Add pairwise energies
    crf.addPairwiseGaussian(my_surfels, 3, valid_ids);

    crf.addPairwiseBilateral(my_surfels, 10, valid_ids);

    int iterations;
    ros::param::get("reg_iteration", iterations);

    ROS_INFO_STREAM("CRF inference!");
    float* resulting_probs = crf.runInference(iterations, 1.0);

    ROS_INFO_STREAM("CRF inference finished!");


    int changed_probs = 0;

    for (int i = 0; i < static_cast<int>(valid_ids.size()); i++) {
        for (int j = 0; j < num_labels; j++) {
            const int id = valid_ids[i];
            // Sometimes it returns nan resulting probs... filter these out
            if (resulting_probs[i * num_labels + j] > 0.0 && resulting_probs[i * num_labels + j] < 1.0) {
                label_prob_frame_out[i][j] = resulting_probs[i * num_labels + j];
                changed_probs++;
            }
        }
    }

    ROS_WARN_STREAM("Changed " << changed_probs << " probs after regularisation out of " << label_prob_out.size()*num_labels);

    // Renormalize distribution to sum 1
    for (int k = 0; k < label_prob_frame_out.size(); ++k) {
        float prob_dist_sum = 0.0;
        for (int cl = 0; cl < num_labels; ++cl) {
            prob_dist_sum += label_prob_frame_out[k][cl];
        }

        // Divide each element by the sum so that they add up to 1
        for (int cl = 0; cl < num_labels; ++cl) {
            label_prob_frame_out[k][cl] /= prob_dist_sum;
        }
    }

    delete [] my_surfels;

    it_reg = 0;
    for(vector<int>::iterator it = inside_indices.begin(); it != inside_indices.end(); it++){
        for (int cl = 0; cl < num_labels; cl++) {
            label_prob_out[*it][cl] = label_prob_frame_out[it_reg][cl];
        }
        it_reg++;
    }   
    ROS_INFO_STREAM("Finish Regularizing frame:");
}

void SemanticFusion::regularizePointcloud(const pcl::PointCloud<pcl::PointXYZRGB> &cloud_in,
                                          const vector<vector<float>> &label_prob_in, 
                                          vector<vector<float>> &label_prob_out){
    
    ROS_INFO_STREAM("Regularizing map:");
    // initialize label_prob_out
    copy(label_prob_in.begin(), label_prob_in.end(), back_inserter(label_prob_out));

    // create the normal estimation instance
    pcl::NormalEstimation<pcl::PointXYZRGB, pcl::Normal> ne;
    pcl::search::KdTree<pcl::PointXYZRGB>::Ptr tree (new pcl::search::KdTree<pcl::PointXYZRGB> ());
    ne.setSearchMethod (tree);
    ne.setRadiusSearch (0.03);

    ne.setInputCloud (cloud_in.makeShared());
    pcl::PointCloud<pcl::Normal>::Ptr cloud_normals (new pcl::PointCloud<pcl::Normal>);
    ne.compute (*cloud_normals);

    // emulate data structure for each cloud's point 
    int surfel_size = 7; 
    float * my_surfels = new float[label_prob_in.size() * surfel_size];

    // fill in surfel data for each point
    for(int i = 0; i < label_prob_in.size(); i++){

        // add x,y,z position as floats on positions 0, 1, 2
        my_surfels[i*surfel_size + 0] = cloud_in.points[i].x;
        my_surfels[i*surfel_size + 1] = cloud_in.points[i].y;
        my_surfels[i*surfel_size + 2] = cloud_in.points[i].z;

        // add 32bit encoded rgb color on position 4
        int colour = cloud_in.points[i].r;
        colour = (colour << 8) + cloud_in.points[i].g;
        colour = (colour << 8) + cloud_in.points[i].b;
        my_surfels[i*surfel_size + 3] = colour;

        // Add x,y,z components of normal vector on positions 8, 9, 10
        my_surfels[i*surfel_size + 4] = cloud_normals->points[i].normal_x;
        my_surfels[i*surfel_size + 5] = cloud_normals->points[i].normal_y;
        my_surfels[i*surfel_size + 6] = cloud_normals->points[i].normal_z;

    }

    vector<int> valid_ids;
    for (int i = 0; i < label_prob_in.size(); i++) {
        valid_ids.push_back(i);
    }

    // generate unary energies
    vector<float> unary_potentials(label_prob_in.size() * num_labels);
    for (int i = 0; i < label_prob_in.size(); i++) {
        for (int j = 0; j < label_prob_in[0].size();j++) {
            unary_potentials[i * num_labels + j] = -log10(label_prob_in[i][j] + 1.0e-6f);
        }
    }

    // CRF
    DenseCRF3D crf((int) cloud_in.points.size(), num_labels, 0.05, 20, 0.1);
    // Add unary energies
    crf.setUnaryEnergy(unary_potentials.data());
    // Add pairwise energies
    crf.addPairwiseGaussian(my_surfels, 3, valid_ids);
    crf.addPairwiseBilateral(my_surfels, 10, valid_ids);

    int iterations;
    ros::param::get("reg_iteration", iterations);

    float* resulting_probs = crf.runInference(iterations, 1.0);

    ROS_INFO_STREAM("CRF inference finished!");

    int changed_probs = 0;

    for (int i = 0; i < static_cast<int>(valid_ids.size()); ++i) {
        for (int j = 0; j < num_labels; ++j) {
            const int id = valid_ids[i];
            // Sometimes it returns nan resulting probs... filter these out
            if (resulting_probs[i * num_labels + j] > 0.0 && resulting_probs[i * num_labels + j] < 1.0) {
                label_prob_out[i][j] = resulting_probs[i * num_labels + j];
                changed_probs++;
            }
        }
    }

    ROS_WARN_STREAM("Changed " << changed_probs << " probs after regularisation out of " << label_prob_out.size()*num_labels);

    // Renormalize distribution to sum 1
    for (int k = 0; k < label_prob_out.size(); ++k) {
        float prob_dist_sum = 0.0;
        for (int cl = 0; cl < num_labels; ++cl) {
            prob_dist_sum += label_prob_out[k][cl];
        }

        // Divide each element by the sum so that they add up to 1
        for (int cl = 0; cl < num_labels; ++cl) {
            label_prob_out[k][cl] /= prob_dist_sum;
        }
    }

    delete [] my_surfels;
    ROS_INFO_STREAM("Finish Regularizing map:");

}

// per pointcloud's point, map each label to a RGB color
void SemanticFusion::createLabelsInRGBPointcloud(const pcl::PointCloud<pcl::PointXYZRGB> &pc, 
                                     const vector<vector<float>> &label_prob,
                                     pcl::PointCloud<pcl::PointXYZL> &labeled_pc,
                                     pcl::PointCloud<pcl::PointXYZRGB> &rgb_labeled_pc){
    // Build XYZL pointcloud
    for (int i = 0; i < pc.points.size(); i++){
        pcl::PointXYZL p;
        p.x = pc.points[i].x;
        p.y = pc.points[i].y;
        p.z = pc.points[i].z;

        int max_label = num_labels + 1;

        float max_label_prob = 1.0f / (num_labels * 1.0f);
        for (int cl = 0; cl < num_labels; cl++){
            if(label_prob[i][cl] > max_label_prob){
                max_label = cl;
                max_label_prob = label_prob[i][cl];
            }
        }

        p.label = (uint32_t) max_label; 
        labeled_pc.push_back(p);

    }

    // Build XYZRGB pointcloud to represent XYZL pointcloud
    for (int i = 0; i < labeled_pc.points.size(); i++){
        pcl::PointXYZRGB p;
        p.x = labeled_pc.points[i].x;
        p.y = labeled_pc.points[i].y;
        p.z = labeled_pc.points[i].z;

        if(labeled_pc.points[i].label > num_labels){
            p.b = 0;
            p.g = 0;
            p.r = 0;
        }
        else{
            cv::Vec3b color = label2bgr.at<cv::Vec3b>(cv::Point(labeled_pc.points[i].label, 0));
            p.b = color.val[0];
            p.g = color.val[1];
            p.r = color.val[2];

        }
        rgb_labeled_pc.push_back(p);

    }

}

// display labeled pointcloud (label mapped to perceivable RGB colors)
void SemanticFusion::displayPointcloud(const pcl::PointCloud<pcl::PointXYZRGB> &pc) {
    sensor_msgs::PointCloud2 pc_disp_msg;
    pcl::toROSMsg(*pc.makeShared(), pc_disp_msg);
    pc_disp_msg.header.frame_id = "map";

    pc_display_pub.publish(pc_disp_msg);

}

void SemanticFusion::loadAndPublishLabeledPointcloud(string base_path){
    string cloud_path = base_path + "cloud.ply";
    string labeled_cloud_path = base_path + "labeled_cloud.ply";
    string labeled_cloud_rgb_path = base_path + "labeled_cloud_rgb.ply";
    string label_probs_path = base_path + "label_probabilities.txt";

    // load global RGB cloud
    pcl::PointCloud<pcl::PointXYZRGB> rgb_cloud; 
    pcl::io::loadPLYFile(cloud_path, rgb_cloud);

    // load labeled cloud
    pcl::PointCloud<pcl::PointXYZL> labeled_pc;
    pcl::io::loadPLYFile(labeled_cloud_path, labeled_pc);

    // initialize label probability structure and load point semantic probabilities
    vector<float> label_prob_init(num_labels, -500.0f); 
    vector<vector<float> > label_prob(rgb_cloud.points.size(), label_prob_init);
    loadPointsProbDist(label_probs_path, label_prob);

    // load and display rgb semantic labels
    pcl::PointCloud<pcl::PointXYZRGB> label_rgb_pc;
    pcl::io::loadPLYFile(labeled_cloud_rgb_path, label_rgb_pc);
    displayPointcloud(label_rgb_pc);

    // create pointcloud message
    sensor_msgs::PointCloud2 labeled_pc_msg;
    pcl::toROSMsg(labeled_pc, labeled_pc_msg);
    labeled_pc_msg.header.frame_id = "map";

    // Create probabilities message
    std_msgs::Float32MultiArray label_prob_msg;
    matrix2multiarray(label_prob, label_prob_msg);

    // Publish both
    graph_semantic::FusedPointcloud fused_pc_msg;
    fused_pc_msg.labelled_pc = labeled_pc_msg;
    fused_pc_msg.label_probs = label_prob_msg;
    fused_pc_pub.publish(fused_pc_msg);

    ROS_INFO_STREAM("Finished loading labeled pc and probabilities from directory");
}

// display camera pose in map frame
void SemanticFusion::displayCameraMarker(Eigen::Matrix4f cam_pose){
    visualization_msgs::Marker marker;
    marker.header.frame_id = "map";
    marker.header.stamp = ros::Time();
    marker.ns = "graph_semantic";
    marker.id = 0;
    marker.type = visualization_msgs::Marker::ARROW;
    marker.action = visualization_msgs::Marker::ADD;

    marker.pose.position.x = cam_pose(0, 3);
    marker.pose.position.y = cam_pose(1, 3);
    marker.pose.position.z = cam_pose(2, 3);

    Eigen::Matrix3f mat = cam_pose.topLeftCorner(3,3);
    Eigen::Quaternionf q(mat);

    marker.pose.orientation.x = q.x();
    marker.pose.orientation.y = q.y();
    marker.pose.orientation.z = q.z();
    marker.pose.orientation.w = q.w();

    marker.scale.x = 0.5;
    marker.scale.y = 0.1;
    marker.scale.z = 0.1;
    marker.color.a = 1.0; // Don't forget to set the alpha!
    marker.color.r = 0.5;
    marker.color.g = 0.5;
    marker.color.b = 0.5;

    marker_pub.publish(marker);
}

// wraps a matrix into a multiarray for data transport
void SemanticFusion::matrix2multiarray(const vector<vector<float>> &label_prob,
                                       std_msgs::Float32MultiArray &msg_out){

    // Initialize layout
    msg_out.layout.data_offset = 0;
    msg_out.layout.dim.push_back(std_msgs::MultiArrayDimension());
    msg_out.layout.dim.push_back(std_msgs::MultiArrayDimension());

    // Fill layout dimensions
    msg_out.layout.dim[0].label = "height";
    msg_out.layout.dim[0].size = (uint) label_prob.size(); // # of pc
    msg_out.layout.dim[0].stride = (uint) (label_prob.size() * label_prob[0].size());

    msg_out.layout.dim[1].label = "width";
    msg_out.layout.dim[1].size = (uint) label_prob[0].size();
    msg_out.layout.dim[1].stride = (uint) label_prob[0].size();

    msg_out.data.clear();
    msg_out.data.resize(msg_out.layout.dim[0].stride, -500.0f); // need not to resize?
    for (int i = 0; i < label_prob.size(); ++i) {
        for (int j = 0; j < label_prob[0].size(); ++j) {
            msg_out.data[j + msg_out.layout.dim[1].stride*i] = label_prob[i][j];
        }
    }


}

// save each point's class probability (for CRF point-wise regularization)
void SemanticFusion::storePointsProbDist(const string &label_probs_path, const vector<vector<float> > &label_prob){
    ofstream myfile;
    myfile.open(label_probs_path);

    for (int i = 0; i < label_prob.size(); i++){
        for (int j = 0; j < label_prob[0].size(); j++){
            myfile << label_prob[i][j] << " ";
        }
        myfile << endl;
    }
    myfile.close();

}

void SemanticFusion::loadPointsProbDist(const string &label_probs_path, vector<vector<float> > &label_prob){
    ifstream myfile; 
    myfile.open(label_probs_path);

    for(int i = 0; i < label_prob.size(); i++){
        for(int j = 0; j < label_prob[0].size(); j++){
            myfile >> label_prob[i][j];
        }
    }

    myfile.close();
}
int main(int argc, char **argv)
{
    ROS_INFO_STREAM("semantic_proj_node Main is running!"); 
    ros::init(argc, argv, "semantic_proj_node");
    string scene_path = "/home/alpha/Kinect_bag/graph_semantic_data/alpha_light_any_angle/"; // to be optimized
    vector<string> base_paths;
    base_paths.push_back(scene_path);

    bool load_existing = false; 
    ros::param::get("load_existing", load_existing);
    

    for (int i = 0; i < base_paths.size(); i++){
        
        SemanticFusion sem_fusion; 
        ROS_INFO_STREAM("SemanticFusion instance created!"); 
        ros::param::get("debug", sem_fusion.debug_mode);

        string base_path = base_paths.at(i);
        if (base_path.back() != '/') base_path += '/';
         if (load_existing){
            sem_fusion.loadAndPublishLabeledPointcloud(base_path);
            ROS_INFO_STREAM("Load existing!"); 
         }
         else{
            pcl::PointCloud<pcl::PointXYZRGB> pc;
            vector<Eigen::Matrix4f> poses;
            vector<string> images;

            sem_fusion.loadPlaceData(base_path, pc, poses, images);
            ros::Duration(0.1).sleep();
            sem_fusion.createFusedSemanticMap(base_path, pc, poses, images);

         }

    }

    return 0;
}